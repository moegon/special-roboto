# AI Chat Feature - User Guide

## ü§ñ Interactive AI Chat in VS Code

The Atlas Pipeline Toolkit now includes a built-in AI chat panel that connects to:
- **LM Studio** (local models)
- **OpenRouter** (cloud models)
- **Custom APIs** (any OpenAI-compatible endpoint)

---

## üöÄ Quick Start

### 1. Open AI Chat

Press `Ctrl+Shift+P` and run:
```
Atlas: Open AI Chat
```

Or use the command palette shortcut.

### 2. Configure Provider

Choose your AI provider:
```
Atlas: Select AI Chat Provider
```

**Options:**
- **LM Studio** - Run models locally (Llama, Mistral, etc.)
- **OpenRouter** - Access GPT-4, Claude, and other cloud models
- **Custom API** - Connect to your own endpoint

---

## ‚öôÔ∏è Configuration

### LM Studio Setup (Local Models)

1. **Install LM Studio:** Download from [lmstudio.ai](https://lmstudio.ai)
2. **Load a model:** Download any model (e.g., Llama 3, Mistral 7B)
3. **Start server:** In LM Studio, click "Start Server" (default: port 1234)

4. **Configure extension:**
   - `atlas.chatProvider` ‚Üí `lmstudio`
   - `atlas.lmStudioEndpoint` ‚Üí `http://localhost:1234/v1/chat/completions`
   - `atlas.lmStudioModel` ‚Üí `local-model` (or your model name)

**Settings (JSON):**
```json
{
  "atlas.chatProvider": "lmstudio",
  "atlas.lmStudioEndpoint": "http://localhost:1234/v1/chat/completions",
  "atlas.lmStudioModel": "llama-3-8b",
  "atlas.chatStreaming": true,
  "atlas.chatTemperature": 0.7,
  "atlas.chatMaxTokens": 2000
}
```

### OpenRouter Setup (Cloud Models)

1. **Get API key:** Sign up at [openrouter.ai](https://openrouter.ai)
2. **Configure extension:**
   - `atlas.chatProvider` ‚Üí `openrouter`
   - `atlas.openRouterApiKey` ‚Üí Your API key
   - `atlas.openRouterModel` ‚Üí `anthropic/claude-3.5-sonnet`

**Settings (JSON):**
```json
{
  "atlas.chatProvider": "openrouter",
  "atlas.openRouterApiKey": "sk-or-...",
  "atlas.openRouterModel": "anthropic/claude-3.5-sonnet",
  "atlas.chatStreaming": true
}
```

**Available Models:**
- `anthropic/claude-3.5-sonnet` - Best for coding
- `openai/gpt-4-turbo` - GPT-4 Turbo
- `openai/gpt-4` - GPT-4
- `meta-llama/llama-3-70b` - Llama 3 70B
- See [openrouter.ai/models](https://openrouter.ai/models) for full list

### Custom API Setup

For any OpenAI-compatible API:

```json
{
  "atlas.chatProvider": "custom",
  "atlas.customApiEndpoint": "https://your-api.com/v1/chat/completions",
  "atlas.customApiKey": "your-api-key",
  "atlas.customApiModel": "your-model-name"
}
```

---

## üí¨ Using the Chat

### Send Messages

1. Type your question in the input field
2. Press `Enter` to send (or click "Send")
3. Use `Shift+Enter` for new lines
4. Responses stream in real-time

### Features

**Clear Chat:**
- Click "Clear" button to start fresh conversation
- Clears message history

**Export Chat:**
- Click "Export" button
- Opens chat log in new Markdown document
- Includes full conversation history

**Streaming Responses:**
- Words appear as they're generated (like ChatGPT)
- Provides immediate feedback
- Can be disabled: `"atlas.chatStreaming": false`

---

## üéõÔ∏è Advanced Settings

### Temperature
Controls randomness (0 = deterministic, 2 = very creative):
```json
{
  "atlas.chatTemperature": 0.7
}
```

**Use cases:**
- `0.2` - Code generation, factual answers
- `0.7` - Balanced (default)
- `1.2` - Creative writing

### Max Tokens
Maximum length of responses:
```json
{
  "atlas.chatMaxTokens": 2000
}
```

- Lower values = shorter, faster responses
- Higher values = longer, more detailed responses
- Costs more with cloud providers

---

## üîß Troubleshooting

### LM Studio Issues

**Problem:** "Failed to connect to LM Studio"
- ‚úÖ Check LM Studio server is running (green indicator)
- ‚úÖ Verify port is 1234 (or update endpoint)
- ‚úÖ Try: `http://127.0.0.1:1234/v1/chat/completions`

**Problem:** "Model not found"
- ‚úÖ Load a model in LM Studio first
- ‚úÖ Check model name matches setting

### OpenRouter Issues

**Problem:** "API key not configured"
- ‚úÖ Set `atlas.openRouterApiKey` in settings
- ‚úÖ Get key from [openrouter.ai](https://openrouter.ai)

**Problem:** "Insufficient credits"
- ‚úÖ Add credits to your OpenRouter account
- ‚úÖ Check balance at dashboard

### Custom API Issues

**Problem:** "Custom API endpoint not configured"
- ‚úÖ Set `atlas.customApiEndpoint` in settings
- ‚úÖ Ensure endpoint follows OpenAI format

**Problem:** "Authentication failed"
- ‚úÖ Check `atlas.customApiKey` is correct
- ‚úÖ Some APIs don't require keys (leave empty)

### General Issues

**Problem:** Slow responses
- ‚úÖ Check internet connection (OpenRouter)
- ‚úÖ Check LM Studio CPU/GPU usage
- ‚úÖ Try smaller model or reduce max tokens

**Problem:** Responses cut off
- ‚úÖ Increase `atlas.chatMaxTokens`
- ‚úÖ LM Studio: check context length in server settings

---

## üéØ Example Use Cases

### Code Assistance
```
User: How do I create a VS Code webview panel in TypeScript?
AI: [Provides detailed TypeScript example with vscode API]
```

### Debugging
```
User: Why is my fetch request returning CORS errors?
AI: [Explains CORS, provides solutions]
```

### Documentation
```
User: Explain this code: [paste code]
AI: [Provides line-by-line explanation]
```

### Refactoring
```
User: Refactor this function to use async/await
AI: [Provides refactored version]
```

---

## üìä Provider Comparison

| Feature | LM Studio | OpenRouter | Custom API |
|---------|-----------|------------|------------|
| **Cost** | Free (local) | Pay per token | Varies |
| **Privacy** | 100% local | Cloud | Depends |
| **Speed** | Fast (local) | Variable | Depends |
| **Models** | Any local | 100+ cloud | Yours |
| **Setup** | Medium | Easy | Varies |
| **Internet** | Not required | Required | Depends |

---

## üîê Privacy & Security

### LM Studio (Local)
- ‚úÖ All data stays on your machine
- ‚úÖ No internet required
- ‚úÖ Full privacy

### OpenRouter / Cloud
- ‚ö†Ô∏è Data sent to third-party servers
- ‚ö†Ô∏è Review provider privacy policies
- ‚ö†Ô∏è Don't share sensitive code/data

### Custom API
- Depends on your deployment
- Control your own data

---

## üÜò Commands Reference

| Command | Description |
|---------|-------------|
| `Atlas: Open AI Chat` | Open the chat panel |
| `Atlas: Select AI Chat Provider` | Change provider (LM Studio/OpenRouter/Custom) |

---

## üí° Tips

1. **Use streaming** for better UX (`atlas.chatStreaming: true`)
2. **Lower temperature** for code generation (0.2-0.3)
3. **Higher temperature** for creative tasks (1.0-1.5)
4. **LM Studio for privacy** - no data leaves your machine
5. **OpenRouter for variety** - access to latest models
6. **Export important chats** - save useful conversations

---

## üöÄ Next Steps

- Try different models to find what works best
- Experiment with temperature settings
- Export useful conversations for reference
- Use chat for code reviews, debugging, learning

---

**Need Help?** Check the Output panel (View ‚Üí Output ‚Üí Atlas Pipeline) for detailed logs.

**Feature Requests?** See our GitHub repository for contributing guidelines.
